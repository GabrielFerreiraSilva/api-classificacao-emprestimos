# API de ClassificaÃ§Ã£o de EmprÃ©stimos

## ğŸ“– Sobre o Projeto

Esta Ã© uma API RESTful desenvolvida com **FastAPI** para classificar a aprovaÃ§Ã£o de emprÃ©stimos financeiros. O projeto utiliza um modelo de Machine Learning (Random Forest) para prever a probabilidade de um cliente ter seu emprÃ©stimo aprovado ou nÃ£o, com base em seus dados pessoais e financeiros.

A aplicaÃ§Ã£o Ã© containerizada com **Docker**, garantindo um ambiente de execuÃ§Ã£o consistente e facilitando o deploy.

## âœ¨ Funcionalidades

-   **PrediÃ§Ã£o de Risco de CrÃ©dito**: Classifica solicitaÃ§Ãµes de emprÃ©stimo em `aprovado` ou `negado`.
-   **API RESTful**: Interface clara e documentada (via Swagger UI) para interaÃ§Ã£o com o modelo.
-   **ContainerizaÃ§Ã£o**: FÃ¡cil setup e deploy com Docker e Docker Compose.
-   **Modelo Robusto**: O modelo foi escolhido apÃ³s uma anÃ¡lise comparativa rigorosa, priorizando a seguranÃ§a contra falsos positivos.

## ğŸ§  O Processo de Machine Learning

Todo o fluxo de treinamento, avaliaÃ§Ã£o e seleÃ§Ã£o do modelo estÃ¡ documentado no notebook `1 - Treinamento e AvaliaÃ§Ã£o do Modelo.ipynb`.

### Fonte de Dados

A base de dados utilizada, `dados_tratados.csv`, foi prÃ©-processada e analisada em um projeto anterior de anÃ¡lise exploratÃ³ria de dados.
> **Link para o projeto de anÃ¡lise de dados:** [Projeto AnÃ¡lise de Dados de EmprÃ©stimos](https://github.com/GabrielFerreiraSilva/analise-de-dados-emprestimos)

### Engenharia de Features

Uma feature importante, `numero_parcelas`, nÃ£o estava presente na base original. Ela foi criada sinteticamente atravÃ©s de um algoritmo que considera o valor do emprÃ©stimo, sua finalidade e o score de crÃ©dito do cliente. Foi adicionado ruÃ­do para garantir maior variabilidade e realismo aos dados.

### Modelagem e AvaliaÃ§Ã£o

Para encontrar o melhor classificador, foram seguidos os seguintes passos:

1.  **PrÃ©-processamento**: Foi criada uma pipeline para codificar variÃ¡veis categÃ³ricas e garantir que o processo fosse aplicado de forma consistente nos dados de treino e teste, evitando *data leakage*.
2.  **Modelos Testados**: Foram avaliados trÃªs algoritmos: **Ãrvore de DecisÃ£o**, **Random Forest** e **XGBoost**.
3.  **Tratamento de Desbalanceamento**: Como a base de dados era desbalanceada, foram testados dois cenÃ¡rios:
    -   **CenÃ¡rio 1**: Uso do parÃ¢metro `class_weight='balanced'` (e seu equivalente no XGBoost) para penalizar erros na classe minoritÃ¡ria.
    -   **CenÃ¡rio 2**: Uso da tÃ©cnica de oversampling **SMOTE** para balancear as classes antes do treinamento.
4.  **MÃ©tricas de AvaliaÃ§Ã£o**: Os 6 modelos resultantes (3 algoritmos x 2 cenÃ¡rios) foram avaliados com base em AcurÃ¡cia, Matriz de ConfusÃ£o, Curva ROC, AUC, Precision, Recall e F1-Score.

### SeleÃ§Ã£o do Modelo

Considerando o **perfil conservador da empresa** em relaÃ§Ã£o a riscos financeiros, o principal critÃ©rio de escolha foi a minimizaÃ§Ã£o de **falsos positivos** (prever "aprovado" para um cliente que nÃ£o deveria ser).

O modelo **Random Forest com `class_weight`** foi o escolhido, pois apresentou o melhor equilÃ­brio entre um baixo nÃºmero de falsos positivos e um bom desempenho geral nas outras mÃ©tricas.

A pipeline final, contendo o prÃ©-processador e o modelo treinado, foi exportada para o arquivo `artifacts/random_forest_class_weight_pipeline.joblib`.

## ğŸ› ï¸ Estrutura do Projeto

```
api-classificacao-emprestimos/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py           # ConfiguraÃ§Ãµes da aplicaÃ§Ã£o (variÃ¡veis de ambiente)
â”‚   â”œâ”€â”€ dto.py              # Data Transfer Objects (Pydantic models) para a API
â”‚   â””â”€â”€ main.py             # LÃ³gica principal da API com FastAPI
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ random_forest_class_weight_pipeline.joblib  # Pipeline do modelo treinado
â”œâ”€â”€ bases/
â”‚   â””â”€â”€ dados_tratados.csv  # Base de dados utilizada
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .env                    # Arquivo de variÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ 1 - Treinamento e AvaliaÃ§Ã£o do Modelo.ipynb # Notebook com o processo de ML
â”œâ”€â”€ docker-compose.yml      # Orquestrador dos containers
â”œâ”€â”€ Dockerfile              # DefiniÃ§Ã£o do container da aplicaÃ§Ã£o
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt        # DependÃªncias Python do projeto
```

## ğŸš€ Como Executar

### PrÃ©-requisitos

-   [Git](https://git-scm.com/)
-   [Docker](https://www.docker.com/get-started)
-   [Docker Compose](https://docs.docker.com/compose/install/)

### InstalaÃ§Ã£o

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone https://github.com/GabrielFerreiraSilva/api-classificacao-emprestimos
    cd api-classificacao-emprestimos
    ```

2.  **Configure as variÃ¡veis de ambiente:**
    Crie um arquivo chamado `.env` na raiz do projeto, copiando o exemplo abaixo.

    ```env
    # .env
    PIPELINE_PATH=artifacts/random_forest_class_weight_pipeline.joblib
    APP_HOST="0.0.0.0"
    APP_PORT=8080
    ```
    *Obs: O `APP_HOST` deve ser `0.0.0.0` para ser acessÃ­vel de fora do container Docker.*

3.  **Inicie a aplicaÃ§Ã£o com Docker Compose:**
    ```bash
    docker-compose up --build -d
    ```

A API estarÃ¡ disponÃ­vel em `http://localhost:8080`. A documentaÃ§Ã£o interativa (Swagger UI) pode ser acessada em `http://localhost:8080/docs`.

## ğŸ”Œ Endpoints da API

### `GET /`

Endpoint raiz para verificar se a API estÃ¡ no ar.

-   **Resposta (200 OK):**
    ```json
    {
      "message": "Bem-vindo Ã  API de Risco de CrÃ©dito. Acesse /docs para a documentaÃ§Ã£o."
    }
    ```

### `GET /health`

Verifica o status da API e se a pipeline do modelo foi carregada com sucesso.

-   **Resposta (200 OK):**
    ```json
    {
      "status": "ok",
      "pipeline_loaded": true
    }
    ```

### `POST /predict`

Recebe os dados de um cliente e retorna a prediÃ§Ã£o de aprovaÃ§Ã£o do emprÃ©stimo.

-   **Corpo da RequisiÃ§Ã£o (Request Body):**
    ```json
    {
      "idade": 24,
      "genero": "feminino",
      "escolaridade": "tecnologo",
      "renda_anual": 100684.0,
      "experiencia_profissional_anos": 3,
      "tipo_moradia": "aluguel",
      "valor_emprestimo": 35000.0,
      "finalidade_emprestimo": "pessoal",
      "taxa_juros_emprestimo": 8.90,
      "percentual_renda_comprometida": 0.35,
      "historico_credito_anos": 2,
      "score_credito": 544,
      "inadimplencia_anterior": "nao",
      "numero_parcelas": 66
    }
    ```

-   **Resposta (200 OK):**
    ```json
    {
      "prediction_status": "aprovado",
      "probability_approved": "94.00%"
    }
    ```

## ğŸ”® PrÃ³ximos Passos

-   [ ] **Implementar SHAP**: Adicionar um endpoint para explicar as prediÃ§Ãµes do modelo utilizando a biblioteca SHAP (SHapley Additive exPlanations).
-   [ ] **Retreinamento PeriÃ³dico**: Criar um pipeline de MLOps para automatizar o retreinamento do modelo com a chegada de novos dados.
-   [ ] **Testes UnitÃ¡rios**: Aumentar a cobertura de testes para garantir a robustez da API.